<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"
  xmlns:atom="http://www.w3.org/2005/Atom"
  xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>BigJun&#39;s Blog</title>
    <link>http://yoursite.com/</link>
    <atom:link href="/rss2.xml" rel="self" type="application/rss+xml"/>
    
    <description>è®°å½•ç”Ÿæ´» åˆ†äº«çŸ¥è¯†</description>
    <pubDate>Mon, 17 Jun 2019 14:11:31 GMT</pubDate>
    <generator>http://hexo.io/</generator>
    
    <item>
      <title>toolkit for project</title>
      <link>http://yoursite.com/2019/06/17/toolkit-for-project/</link>
      <guid>http://yoursite.com/2019/06/17/toolkit-for-project/</guid>
      <pubDate>Mon, 17 Jun 2019 08:42:18 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p><a href="https://blog.csdn.net/qq_15809599/article/details/61239292" target="_blank" rel="noopener">è§£å†³gitæŒ‡ä»¤æ›´æ–°è¿œç¨‹ä»“åº“githubæ—¶æ¯æ¬¡éƒ½è¦è¾“å…¥ç”¨æˆ·åå’Œå¯†ç é—®é¢˜</a></p><p>å¯¼å‡ºå·²æœ‰ç¯å¢ƒï¼š<br>conda env export &gt; environment.yaml </p><p>å°†environment.yamlæ–‡ä»¶å¤åˆ¶åˆ°æ–°ä¸»æœºä¸Šä¹‹å<br>æ ¹æ®ç´¢å¼•æ–‡ä»¶åˆ›å»ºå¹¶æ¢å¤è™šæ‹Ÿç¯å¢ƒï¼š<br>conda env create -n your_env_name -f environment.yaml</p><p><a href="https://www.jianshu.com/p/b86c17057da8" target="_blank" rel="noopener">condaç¯å¢ƒè½¬ç§»å¤åˆ¶å’ŒpipåŒ…çš„è½¬ç§»å¤åˆ¶</a></p><p><a href="https://blog.csdn.net/qq_35860352/article/details/80685175" target="_blank" rel="noopener">Condaç¯å¢ƒç§»æ¤ï¼ˆå…‹éš†ï¼‰çš„æ–¹æ³•</a></p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/06/17/toolkit-for-project/#disqus_thread</comments>
    </item>
    
    <item>
      <title>DL_GANs</title>
      <link>http://yoursite.com/2019/05/05/DL-GANs/</link>
      <guid>http://yoursite.com/2019/05/05/DL-GANs/</guid>
      <pubDate>Sun, 05 May 2019 11:56:52 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h1><p>The idea behind GANs is that you have two networks, a generator  ğº  and a discriminator  ğ· , competing against each other. The generator makes â€œfakeâ€ data to pass to the discriminator. The discriminator also sees real training data and predicts if the data itâ€™s received is real or fake.  </p><blockquote><ul><li>The generator is trained to fool the discriminator, it wants to output data that looks as close as possible to real, training data.   </li><li>The discriminator is a <strong>classifier</strong> that is trained to figure out which data is real and which is fake.</li></ul></blockquote>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/05/05/DL-GANs/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Attention</title>
      <link>http://yoursite.com/2019/04/25/DL_Attention/</link>
      <guid>http://yoursite.com/2019/04/25/DL_Attention/</guid>
      <pubDate>Thu, 25 Apr 2019 08:32:47 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/04/25/DL_Attention/#disqus_thread</comments>
    </item>
    
    <item>
      <title>python</title>
      <link>http://yoursite.com/2019/04/24/python/</link>
      <guid>http://yoursite.com/2019/04/24/python/</guid>
      <pubDate>Wed, 24 Apr 2019 12:31:38 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><h3 id="Numpyæ•°ç»„ä¸èƒ½ç›´æ¥åšåˆ¤æ–­"><a href="#Numpyæ•°ç»„ä¸èƒ½ç›´æ¥åšåˆ¤æ–­" class="headerlink" title="Numpyæ•°ç»„ä¸èƒ½ç›´æ¥åšåˆ¤æ–­"></a>Numpyæ•°ç»„ä¸èƒ½ç›´æ¥åšåˆ¤æ–­</h3><ul><li><p>å¦‚æœç›´æ¥ä½¿ç”¨np.ndarrayç±»å‹å˜é‡ç›´æ¥åšåˆ¤æ–­è¯­å¥ï¼ˆå¦‚ä¸‹ï¼Œ<code>b</code>æ˜¯å¦æœ‰å€¼ï¼‰ï¼Œåˆ™ä¼šæŠ¥é”™ï¼š<code>The true value of an array with more than one element is ambiguous(å…·æœ‰å¤šä¸ªå…ƒç´ çš„æ•°ç»„çš„çœŸå€¼æ˜¯ä¸æ˜ç¡®çš„!)</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">a = tuple([1,2,3]) #type: tuple </span><br><span class="line">b = np.array(a)   #type: ndarray</span><br><span class="line">if a:   #can pass</span><br><span class="line">print(a)   </span><br><span class="line">if b:   #raise error</span><br><span class="line">print(b)</span><br></pre></td></tr></table></figure></li><li><p>è§£å†³æ–¹æ³•ï¼šå°†<code>if b</code>â€”â€”&gt;<code>if b is not None:</code>æˆ–<code>if list(b)/tuple(b):</code>ã€‚</p></li></ul><h3 id="argparseæ¨¡å—ä½¿ç”¨"><a href="#argparseæ¨¡å—ä½¿ç”¨" class="headerlink" title="argparseæ¨¡å—ä½¿ç”¨"></a>argparseæ¨¡å—ä½¿ç”¨</h3><h3 id="ä½¿ç”¨osæ¨¡å—åˆ›å»ºæ–‡ä»¶å¤¹"><a href="#ä½¿ç”¨osæ¨¡å—åˆ›å»ºæ–‡ä»¶å¤¹" class="headerlink" title="ä½¿ç”¨osæ¨¡å—åˆ›å»ºæ–‡ä»¶å¤¹"></a>ä½¿ç”¨<a href="http://www.runoob.com/python/os-file-methods.html" target="_blank" rel="noopener">osæ¨¡å—</a>åˆ›å»ºæ–‡ä»¶å¤¹</h3><blockquote><p>ä¸€èˆ¬å…ˆä½¿ç”¨<code>os.path.exists(path)</code>æ¥æ£€æŸ¥ç›¸åº”æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨</p><ol><li>ä½¿ç”¨<code>os.mkdir(path)</code>åˆ›å»ºç›®å½•ï¼›</li><li>ä½¿ç”¨<code>os.makedirs(path)</code>é€’å½’åˆ›å»ºç›®å½•ï¼›</li></ol></blockquote><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">if not os.path.exists(path):</span><br><span class="line">os.makedirs(path)</span><br></pre></td></tr></table></figure></code></pre><h3 id="å¤šç»´æ•°ç»„å¢åŠ ç»´åº¦"><a href="#å¤šç»´æ•°ç»„å¢åŠ ç»´åº¦" class="headerlink" title="å¤šç»´æ•°ç»„å¢åŠ ç»´åº¦"></a>å¤šç»´æ•°ç»„å¢åŠ ç»´åº¦</h3><blockquote><p>mean_X[:, None]<br>mean_X[:, np.newaxis]<br>mean_X = np.expand_dims(mean_X, axis=1)</p></blockquote><h2 id="Develop"><a href="#Develop" class="headerlink" title="Develop"></a>Develop</h2><h3 id="pythonåŒ…ä¸­-init-py"><a href="#pythonåŒ…ä¸­-init-py" class="headerlink" title="pythonåŒ…ä¸­__init__.py"></a>pythonåŒ…ä¸­<code>__init__.py</code></h3><ul><li>å°†è¯¥ç›®å½•ä½œä¸ºPython packageçš„æ ‡è¯†ï¼›  </li><li>å®šä¹‰packageä¸­çš„<code>_all_</code>,ç”¨äºæ¨¡ç³Šå¯¼å…¥ï¼›   </li><li><a href="https://blog.csdn.net/qq_40794377/article/details/80273668" target="_blank" rel="noopener">ä¼ é€é—¨</a></li></ul><h3 id="sysä¸osæ¨¡å—"><a href="#sysä¸osæ¨¡å—" class="headerlink" title="sysä¸osæ¨¡å—"></a><a href="https://www.zhihu.com/question/31843617" target="_blank" rel="noopener">sysä¸osæ¨¡å—</a></h3><blockquote><p>os: This module provides a portable way of using <strong>operating system</strong> dependent functionality.<br>sys: This module provides access to some variables used or maintained by the <strong>interpreter</strong> and to functions that interact strongly with the interpreter.<br>osæ¨¡å—è´Ÿè´£ç¨‹åºä¸æ“ä½œç³»ç»Ÿçš„äº¤äº’ï¼Œæä¾›äº†è®¿é—®æ“ä½œç³»ç»Ÿåº•å±‚çš„æ¥å£;sysæ¨¡å—è´Ÿè´£ç¨‹åºä¸pythonè§£é‡Šå™¨çš„äº¤äº’ï¼Œæä¾›äº†ä¸€ç³»åˆ—çš„å‡½æ•°å’Œå˜é‡ï¼Œç”¨äº<strong>æ“æ§pythonçš„è¿è¡Œæ—¶ç¯å¢ƒ</strong>ã€‚</p></blockquote><h3 id="Pythonä¸­dist-packageså’Œsite-packagesåŒºåˆ«"><a href="#Pythonä¸­dist-packageså’Œsite-packagesåŒºåˆ«" class="headerlink" title="Pythonä¸­dist-packageså’Œsite-packagesåŒºåˆ«"></a><a href="https://blog.csdn.net/huiseguiji1/article/details/45111891" target="_blank" rel="noopener">Pythonä¸­dist-packageså’Œsite-packagesåŒºåˆ«</a></h3><ul><li>sudo apt-get install å®‰è£…çš„packageå­˜æ”¾åœ¨ /usr/lib/python2.7/dist-packagesç›®å½•ä¸­    </li><li>pip æˆ–è€… easy_installå®‰è£…çš„packageå­˜æ”¾åœ¨/usr/local/lib/python2.7/dist-packagesç›®å½•    </li><li>æ‰‹åŠ¨ä»æºä»£ç å®‰è£…çš„packageå­˜æ”¾åœ¨site-packagesç›®å½•ä¸­;</li></ul><h3 id="å‘½ä»¤è¡Œè¿è¡Œç¨‹åºå¯é€‰é¡¹ï¼špython-h"><a href="#å‘½ä»¤è¡Œè¿è¡Œç¨‹åºå¯é€‰é¡¹ï¼špython-h" class="headerlink" title="å‘½ä»¤è¡Œè¿è¡Œç¨‹åºå¯é€‰é¡¹ï¼špython -h"></a>å‘½ä»¤è¡Œè¿è¡Œç¨‹åºå¯é€‰é¡¹ï¼š<code>python -h</code></h3><ul><li><code>$ python -E file.py</code>ï¼šå¿½ç•¥æ‰€æœ‰<code>PYTHON*</code>ç¯å¢ƒå˜é‡,å¦‚<code>PYTHONPATH</code>;</li><li><code>$ python -m pdb/ipdb file.py</code>ï¼šè°ƒè¯•æ¨¡å¼ï¼›</li></ul><h3 id="pdbè°ƒè¯•"><a href="#pdbè°ƒè¯•" class="headerlink" title="pdbè°ƒè¯•"></a>pdbè°ƒè¯•</h3><ul><li><a href="https://blog.csdn.net/qingkong1994/article/details/80038199" target="_blank" rel="noopener">å¸¸ç”¨å‘½ä»¤</a></li></ul><h2 id="Common-errors"><a href="#Common-errors" class="headerlink" title="Common errors"></a>Common errors</h2><h3 id="invalid-syntax"><a href="#invalid-syntax" class="headerlink" title="invalid syntax"></a>invalid syntax</h3><ul><li>å¦‚æœåœ¨æ˜¾ç¤ºé”™è¯¯å¤„è¯­æ³•æ­£ç¡®ï¼Œè¯·æ£€æŸ¥å‰ä¸€è¯­å¥æ˜¯å¦æ¼äº†æ‹¬å·ï¼›</li></ul>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/04/24/python/#disqus_thread</comments>
    </item>
    
    <item>
      <title>posts_supplement</title>
      <link>http://yoursite.com/2019/04/14/1posts-supplement/</link>
      <guid>http://yoursite.com/2019/04/14/1posts-supplement/</guid>
      <pubDate>Sun, 14 Apr 2019 08:40:37 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><p></p><h2 id="1">Transform learning</h2><img src="/2019/04/14/1posts-supplement/posts-supplement/1.png" alt=""><p></p><p></p><h2 id="2">Convolutional Autoencoder: Transpose convolution</h2><img src="/2019/04/14/1posts-supplement/posts-supplement/2.png" alt=""><p></p><p></p><h2 id="3">Convolutional Autoencoderï¼šUpsampleing + Convolutions</h2><img src="/2019/04/14/1posts-supplement/posts-supplement/3.png" alt=""><p></p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/04/14/1posts-supplement/#disqus_thread</comments>
    </item>
    
    <item>
      <title>CNNs</title>
      <link>http://yoursite.com/2019/04/06/DL_CNNs/</link>
      <guid>http://yoursite.com/2019/04/06/DL_CNNs/</guid>
      <pubDate>Sat, 06 Apr 2019 07:03:59 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h1><h2 id="Image-Classification-Steps"><a href="#Image-Classification-Steps" class="headerlink" title="Image Classification Steps"></a>Image Classification Steps</h2><ul><li>General Steps<blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/6.png" alt=""></p></blockquote></li></ul><h2 id="the-advantage-of-CNNs"><a href="#the-advantage-of-CNNs" class="headerlink" title="the advantage of CNNs"></a>the advantage of CNNs</h2><ul><li><p>MLPs &amp;&amp; CNNsï¼šFully connected &amp;&amp; Local connected<br><img src="/2019/04/06/DL_CNNs/CNNs/10.png" alt=""></p></li><li><p><strong>Local connected/Sparsely connected</strong><br><img src="/2019/04/06/DL_CNNs/CNNs/11.png" alt=""><img src="/2019/04/06/DL_CNNs/CNNs/12.png" alt=""></p></li><li><p><strong>Weights sharing</strong><br><img src="/2019/04/06/DL_CNNs/CNNs/13.png" alt=""></p></li></ul><h2 id="Basic-Conceptâ€“Ng"><a href="#Basic-Conceptâ€“Ng" class="headerlink" title="Basic Conceptâ€“Ng"></a>Basic Conceptâ€“Ng</h2><blockquote><p><a href="[http://ai-start.com/dl2017/html/lesson4-week1.html]">kernelã€Paddingã€Stridã€Convolutionã€Pooling</a></p></blockquote><h2 id="the-structure-of-CNNs"><a href="#the-structure-of-CNNs" class="headerlink" title="the structure of CNNs"></a>the structure of CNNs</h2><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/9.png" alt=""> </p></blockquote><h2 id="Autoencoders-Encoders-2-Decoders"><a href="#Autoencoders-Encoders-2-Decoders" class="headerlink" title="Autoencoders/Encoders-2-Decoders"></a>Autoencoders/Encoders-2-Decoders</h2><blockquote><p>The key point is to leverage this compressed representation  </p></blockquote><ul><li>Normal images Reconstructuin<blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/14.png" alt=""></p></blockquote></li><li><p>Denoising Autoencoder</p><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/15.png" alt="">  </p></blockquote></li><li><p>Decoderï¼š1) <a href="https://bigjun777.github.io/2019/04/14/posts-supplement/#2" target="_blank" rel="noopener">Transpose Convolution</a>; 2) <a href="https://bigjun777.github.io/2019/04/14/posts-supplement/#3" target="_blank" rel="noopener">Upsampling + Convolutions</a></p></li></ul><h2 id="Transfer-Learning"><a href="#Transfer-Learning" class="headerlink" title="Transfer Learning"></a>Transfer Learning</h2><blockquote><p>Transfer learning involves taking a pre-trained neural network and adapting the neural network to a new, different data set.</p></blockquote><ul><li><p>Four main cases    </p><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/19.png" alt="">Take a look <a href="https://bigjun777.github.io/2019/04/14/posts-supplement/#1" target="_blank" rel="noopener">here</a> for more detail.</p></blockquote></li><li><p>Coding part: <strong>Load the pre-trained model, modefied the model as you want, freeze specified parameters if necessary(<code>requires_grad</code>), specify optimiser if necessary</strong>  </p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"># Load the pretrained model from pytorch</span><br><span class="line">vgg16 = torchvision.models.vgg16(pretrained=True)</span><br><span class="line"># print out the model structure, see the picture below</span><br><span class="line">print(vgg16)</span><br><span class="line">print(vgg16.classifier[6].in_features) </span><br><span class="line"># Freeze training for all &quot;features&quot; layers</span><br><span class="line">for param in vgg16.features.parameters():</span><br><span class="line">   param.requires_grad = False</span><br><span class="line"># create a new classifer</span><br><span class="line">import torch.nn as nn</span><br><span class="line">n_inputs = vgg16.classifier[6].in_features</span><br><span class="line"># add last linear layer (n_inputs -&gt; 5 flower classes)</span><br><span class="line"># new layers automatically have requires_grad = True</span><br><span class="line">last_layer = nn.Linear(n_inputs, len(classes))</span><br><span class="line">vgg16.classifier[6] = last_layer</span><br><span class="line"># specify optimizer (stochastic gradient descent) and learning rate = 0.001</span><br><span class="line">optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)</span><br></pre></td></tr></table></figure><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/20.png" alt=""></p></blockquote><h2 id="Style-Transfer"><a href="#Style-Transfer" class="headerlink" title="Style Transfer"></a>Style Transfer</h2></li></ul><h2 id="Weight-Initialization"><a href="#Weight-Initialization" class="headerlink" title="Weight Initialization"></a><a href="https://github.com/udacity/deep-learning-v2-pytorch/blob/master/weight-initialization/weight_initialization_solution.ipynb" target="_blank" rel="noopener">Weight Initialization</a></h2><blockquote><p>Having good initial weights can place the neural network close to the optimal solution. This allows the neural network to come to the best solution quicker.</p></blockquote><blockquote><p>If every weight is the same(<strong>constant weights</strong>), all the neurons at each layer are producing the same output. This makes it hard to decide which weights to adjust.</p></blockquote><blockquote><p>Commonly, we can use <strong>Uniform Initialization</strong>ã€<strong>Normal Initialization</strong></p></blockquote><h2 id="CNNä¸­å…¨è¿æ¥å±‚ä½œç”¨"><a href="#CNNä¸­å…¨è¿æ¥å±‚ä½œç”¨" class="headerlink" title="CNNä¸­å…¨è¿æ¥å±‚ä½œç”¨"></a>CNNä¸­å…¨è¿æ¥å±‚ä½œç”¨</h2><ul><li><a href="https://www.zhihu.com/question/41037974" target="_blank" rel="noopener">å…¨è¿æ¥å±‚ä½œç”¨</a></li></ul><h1 id="Database"><a href="#Database" class="headerlink" title="Database"></a>Database</h1><h2 id="MNIST"><a href="#MNIST" class="headerlink" title="MNIST"></a>MNIST</h2><ul><li>A hand-written digits dataset:  clean.Centered, heavily pre-processed images<br><img src="/2019/04/06/DL_CNNs/CNNs/1.png" alt=""></li><li>Visualize the data: 28x28 pixels1<br><img src="/2019/04/06/DL_CNNs/CNNs/2.png" alt=""></li></ul><h2 id="CIFAR-10"><a href="#CIFAR-10" class="headerlink" title="CIFAR-10"></a>CIFAR-10</h2><ul><li>Small color images that fall into one of ten classes:60000 images(32x32)<br><img src="/2019/04/06/DL_CNNs/CNNs/8.png" alt=""></li></ul><h2 id="ImageNet"><a href="#ImageNet" class="headerlink" title="ImageNet"></a>ImageNet</h2><h1 id="Data-processsing"><a href="#Data-processsing" class="headerlink" title="Data processsing"></a>Data processsing</h1><h2 id="Data-Normalization"><a href="#Data-Normalization" class="headerlink" title="Data Normalization"></a>Data Normalization</h2><ul><li>basic<br><img src="/2019/04/06/DL_CNNs/CNNs/3.png" alt=""></li></ul><h2 id="Data-flattened"><a href="#Data-flattened" class="headerlink" title="Data flattened"></a>Data flattened</h2><ul><li>To input the data into <strong>MLPs(Multi-Layer Perceptrons)</strong>,you need to convert a maticx to a vector;<br><img src="/2019/04/06/DL_CNNs/CNNs/4.png" alt=""><img src="/2019/04/06/DL_CNNs/CNNs/5.png" alt=""></li></ul><h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a><a href="https://pytorch.org/docs/stable/torchvision/transforms.html" target="_blank" rel="noopener">Data Augmentation</a></h2><ul><li><p>To deal with:</p><blockquote><p>Scale Invariance;Rotation Invariance;Translation Invariance.</p></blockquote>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># convert data to a normalized torch.FloatTensor</span><br><span class="line">transform = transforms.Compose([</span><br><span class="line">    transforms.RandomHorizontalFlip(), # randomly flip and rotate</span><br><span class="line">    transforms.RandomRotation(10),</span><br><span class="line">    transforms.ToTensor(),  # Convert a PIL Image or numpy.ndarray to tensor.</span><br><span class="line">    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))</span><br><span class="line">    ])</span><br></pre></td></tr></table></figure></li></ul><h1 id="Coding-Part"><a href="#Coding-Part" class="headerlink" title="Coding Part"></a>Coding Part</h1><h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><ul><li><p><a href="https://pytorch.org/docs/stable/torch.html#module-torch" target="_blank" rel="noopener">Pytorch Package</a>    </p><blockquote><p> Pytorch is Python package that provides two high-level features:   </p><ol><li>Tensor computation (like NumPy) with strong GPU acceleration   </li><li>Deep neural networks built on a tape-based autograd system</li></ol></blockquote></li><li><p><a href="https://pytorch.org/docs/stable/torchvision/index.html" target="_blank" rel="noopener">torchvision</a>    </p><blockquote><p>The <code>torchvision</code> package consists of <strong>pupular datasetsã€model architecturesã€and common image transformations</strong> for computer vision;</p></blockquote></li><li><p>Import necessary libraries for working with data and Pytorch</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.nn.functional as F</span><br><span class="line">import numpy as np</span><br><span class="line">from torchvision import datasets</span><br><span class="line">import torchvision.transforms as transforms</span><br></pre></td></tr></table></figure></li></ul><h2 id="Load-the-Data"><a href="#Load-the-Data" class="headerlink" title="Load the Data"></a>Load the Data</h2><ul><li><p>Common database: <code>torchvision.transforms.</code>ã€<code>torchvision.datasets.</code>ã€<code>torch.utils.data.Dataloader</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">transform = transforms.ToTensor()  or  transforms.Compose([... ,...])</span><br><span class="line">train_data = torchvision.datasets.MNIST(root=&apos;data&apos;, train=True, download=True, transform=transform)</span><br><span class="line">test_data = torchvision.datasets.MNIST(root=&apos;data&apos;, train=False, download=True, transform=transform)</span><br><span class="line">train_loader = torch.utils.data.Dataloader(train_data, batch_size=20, num_workers=0)</span><br><span class="line">test_loader = torch.utils.data.Dataloader(test_data, batch_size=20, num_workers=0)</span><br></pre></td></tr></table></figure></li><li><p>You can define a new Imagedatas class to load data from a directory: like <a href="https://pytorch.org/docs/stable/torchvision/datasets.html#imagefolder" target="_blank" rel="noopener">ImageFolder</a></p><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/17.png" alt=""></p></blockquote></li></ul><h2 id="Visualize-the-Data"><a href="#Visualize-the-Data" class="headerlink" title="Visualize the Data"></a>Visualize the Data</h2><ul><li><p>Grayï¼š<code>matplotlib.pyplot</code>ã€<a href="https://matplotlib.org/api/_as_gen/matplotlib.figure.Figure.html" target="_blank" rel="noopener">plt.figure()</a>ã€<a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.imshow.html" target="_blank" rel="noopener">plt.imshow()</a>   </p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line">dataiter = iter(train_loader)</span><br><span class="line">images, labels = dataiter.next()</span><br><span class="line">images = images.numpy()# from torch to numpy</span><br><span class="line"></span><br><span class="line">fig = plt.figure(figsize=(25,4))</span><br><span class="line">for idx in np.arange(20):</span><br><span class="line">ax = fig.add_subplot(2, 20/2, id+1, xticks=[], yticks=[])</span><br><span class="line">ax.imshow(np.squeeze(images[idx], cmap=&apos;gray&apos;))</span><br><span class="line">ax.set_title(str(labels[idx].item))</span><br></pre></td></tr></table></figure></li><li><p>RGB</p><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/18.png" alt=""></p></blockquote></li></ul><ul><li>Single image annotation    <blockquote><p><a href="https://matplotlib.org/api/_as_gen/matplotlib.pyplot.annotate.html" target="_blank" rel="noopener">matplotlib.pyplot.annotate</a>ã€<a href="https://blog.csdn.net/wizardforcel/article/details/54782628" target="_blank" rel="noopener">Matplotlib ä¸­æ–‡ç”¨æˆ·æŒ‡å— 4.5 æ ‡æ³¨</a><img src="/2019/04/06/DL_CNNs/CNNs/16.png" alt=""></p></blockquote></li></ul><h2 id="Define-the-Network-Architecture"><a href="#Define-the-Network-Architecture" class="headerlink" title="Define the Network Architecture"></a>Define the Network <a href="https://pytorch.org/docs/stable/nn.html" target="_blank" rel="noopener">Architecture</a></h2><ul><li><p><a href="https://pytorch.org/docs/stable/nn.html?highlight=linear#torch.nn.Linear" target="_blank" rel="noopener">Linear layers</a></p><blockquote><p>torch.nn.Linear(in_features, out_features, bias=True)   </p><blockquote><p>Input: (N, *, in_features)(N,âˆ—,in_features) where \âˆ— means any number of additional dimensions.</p></blockquote></blockquote></li><li><p><a href="[https://pytorch.org/docs/stable/nn.html#conv2d]">Convolutional Layers</a>    </p><blockquote><p><img src="/2019/04/06/DL_CNNs/CNNs/7.png" alt=""></p></blockquote></li><li><p>[activationã€dropout function][f]</p></li></ul><h2 id="Specify-Loss-Function-and-Optimizeroptim"><a href="#Specify-Loss-Function-and-Optimizeroptim" class="headerlink" title="Specify Loss Function and Optimizeroptim"></a>Specify <a href="https://pytorch.org/docs/stable/nn.html#loss-functions" target="_blank" rel="noopener">Loss Function</a> and Optimizer<a href="https://pytorch.org/docs/stable/optim.html" target="_blank" rel="noopener">optim</a></h2><ul><li>Commonï¼šjust use existed class: like <code>nn.CrossEntropyLoss()</code>. You can also define your own Loss function, it is commonly defined as a class.     <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = torch.optim.SGD(model.parameters(), lr = 0.01)</span><br></pre></td></tr></table></figure></li></ul><h2 id="Train-the-Network"><a href="#Train-the-Network" class="headerlink" title="Train the Network"></a>Train the Network</h2><blockquote><p>The steps for training/learning from a batch of data are described in the comments below:</p><pre><code>1. Clear the gradients of all optimized variables.2. Forward pass: compute predicted outputs by passing inputs to the model.3. Calculate the loss.4. Backward pass: compute gradient of the loss with respect to model parameters.5. Perform a single optimization step(parameter update).6. Updata averge training loss.</code></pre></blockquote><ul><li>Basic processï¼šprep model for training <code>model.train()</code> ã€<code>model.eval()</code>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">for data, target in train_loader:</span><br><span class="line">    # clear the gradients of all optimized variables</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    # forward pass: compute predicted outputs by passing inputs to the model</span><br><span class="line">    output = model(data)</span><br><span class="line">    # calculate the loss</span><br><span class="line">    loss = criterion(output, target)</span><br><span class="line">    # backward pass: compute gradient of the loss with respect to model parameters</span><br><span class="line">    loss.backward()</span><br><span class="line">    # perform a single optimization step (parameter update)</span><br><span class="line">    optimizer.step()</span><br><span class="line">    # update running training loss</span><br><span class="line">    train_loss += loss.item()*data.size(0)</span><br></pre></td></tr></table></figure></li></ul>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/04/06/DL_CNNs/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Notes of Manipulation class</title>
      <link>http://yoursite.com/2019/03/25/Notes-of-Manipulation-class/</link>
      <guid>http://yoursite.com/2019/03/25/Notes-of-Manipulation-class/</guid>
      <pubDate>Mon, 25 Mar 2019 12:30:01 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Matlab-Coding"><a href="#Matlab-Coding" class="headerlink" title="Matlab Coding"></a>Matlab Coding</h1><h2 id="è¾“å‡º"><a href="#è¾“å‡º" class="headerlink" title="è¾“å‡º"></a>è¾“å‡º</h2><ul><li><code>fprintf(&#39;...&#39;)</code>ï¼šè¾“å‡ºå­—ç¬¦ï¼›</li></ul><h2 id="æå–æ•°ç»„ã€çŸ©é˜µä¸­å…ƒç´ "><a href="#æå–æ•°ç»„ã€çŸ©é˜µä¸­å…ƒç´ " class="headerlink" title="æå–æ•°ç»„ã€çŸ©é˜µä¸­å…ƒç´ "></a>æå–æ•°ç»„ã€çŸ©é˜µä¸­å…ƒç´ </h2><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ a = A(1); b = B(:,1)</span><br></pre></td></tr></table></figure></code></pre><h2 id="çŸ©é˜µè¿ç®—ï¼šç‚¹ä¹˜ã€é€†ã€è½¬ç½®ã€è¡Œåˆ—å¼"><a href="#çŸ©é˜µè¿ç®—ï¼šç‚¹ä¹˜ã€é€†ã€è½¬ç½®ã€è¡Œåˆ—å¼" class="headerlink" title="çŸ©é˜µè¿ç®—ï¼šç‚¹ä¹˜ã€é€†ã€è½¬ç½®ã€è¡Œåˆ—å¼"></a>çŸ©é˜µè¿ç®—ï¼šç‚¹ä¹˜ã€é€†ã€è½¬ç½®ã€è¡Œåˆ—å¼</h2><pre><code><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ ans = dot(a,b)</span><br><span class="line">$ ans = inv(T)</span><br><span class="line">$ ans = T&apos;</span><br><span class="line">$ ans = det(T)</span><br></pre></td></tr></table></figure></code></pre><h2 id="ç»˜å›¾"><a href="#ç»˜å›¾" class="headerlink" title="ç»˜å›¾"></a>ç»˜å›¾</h2><ul><li><code>plot(x[,y][,&#39;r&#39;])</code>ï¼šç›´æ¥ç»˜åˆ¶å›¾åƒï¼›   </li><li><code>subplot(221)</code>: å­çª—å£ç»˜åˆ¶å›¾åƒï¼›   </li><li><code>title(&#39;helloworld&#39;)</code>: è®¾ç½®æ ‡é¢˜ï¼›   </li><li><code>legend(&#39;1&#39;,&#39;2&#39;,&#39;3&#39;)</code>: æŒ‰ç»˜åˆ¶é¡ºåºç»™å›¾åƒæ ‡æ³¨ï¼›  </li><li><code>axis equal; axis([0 5 0 5])</code>: è®¾ç½®è½´åˆ»åº¦èŒƒå›´</li><li><code>figure(&#39;NumberTitle&#39;, &#39;off&#39;, &#39;Name&#39;, &#39;abc&#39;)</code>ï¼šéšè—æ ‡é¢˜å·ç ï¼Œè®¾ç½®æ ‡é¢˜ï¼›</li></ul><h2 id="å…¶ä»–"><a href="#å…¶ä»–" class="headerlink" title="å…¶ä»–"></a>å…¶ä»–</h2><ul><li><code>tic, ...(æ‰§è¡Œç¨‹åº), toc</code>ï¼šè®¡ç®—ç¨‹åºæ‰§è¡Œæ—¶é—´ï¼›  </li><li><code>edit file.m</code>ï¼šæ‰“å¼€æ–‡ä»¶ï¼›</li></ul><h1 id="2DPose"><a href="#2DPose" class="headerlink" title="2DPose"></a>2DPose</h1><h2 id="Positon-and-Pose"><a href="#Positon-and-Pose" class="headerlink" title="Positon and Pose"></a>Positon and Pose</h2><ul><li>How to describe a point and pose? <img src="/2019/03/25/Notes-of-Manipulation-class/1.png" alt=""></li></ul><h2 id="Relative-Positions"><a href="#Relative-Positions" class="headerlink" title="Relative Positions"></a>Relative Positions</h2><ul><li>How to transform vector from one frame to another?<img src="/2019/03/25/Notes-of-Manipulation-class/2.png" alt=""></li></ul><h2 id="Relative-Poses"><a href="#Relative-Poses" class="headerlink" title="Relative Poses"></a>Relative Poses</h2><ul><li><p>How to calculate the relative points or poses?<img src="/2019/03/25/Notes-of-Manipulation-class/3.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/4.png" alt=""></p></li><li><p>Pose algebra<img src="/2019/03/25/Notes-of-Manipulation-class/5.png" alt=""></p></li></ul><h2 id="Describing-rotation"><a href="#Describing-rotation" class="headerlink" title="Describing rotation"></a>Describing rotation</h2><ul><li><p>How to calculate the rotation?<img src="/2019/03/25/Notes-of-Manipulation-class/6.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/7.png" alt=""></p></li><li><p>Rotation matix<img src="/2019/03/25/Notes-of-Manipulation-class/8.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/9.png" alt=""></p></li></ul><h2 id="Describing-rotation-and-translation"><a href="#Describing-rotation-and-translation" class="headerlink" title="Describing rotation and translation"></a>Describing rotation and translation</h2><ul><li>Homogeneous transform<img src="/2019/03/25/Notes-of-Manipulation-class/10.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/11.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/12.png" alt=""></li></ul><h2 id="Coding-Part"><a href="#Coding-Part" class="headerlink" title="Coding Part"></a>Coding Part</h2><ul><li><p><code>rot2()</code>ï¼š2 dimensional rotation matrix</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rot2(0.2) </span><br><span class="line">rot2(30, &apos;deg&apos;)</span><br></pre></td></tr></table></figure><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/19.png" alt=""></p></li><li><p><code>trot2()</code>ï¼šhomogeneous 2 dimensional rotation matrix</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trot2(30, &apos;deg&apos;)</span><br></pre></td></tr></table></figure><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/20.png" alt=""></p></li><li><p><code>transl2()</code>ï¼š homogeneous transformation representing puretranslation</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">transl2(x,y)</span><br></pre></td></tr></table></figure><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/22.png" alt=""></p></li><li><p><code>se2()</code>ï¼š homogeneous transform matrix: providing the translation in the x and y directions as well as the angle to be rotated</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">se2(x,y,angle,&apos;deg&apos;)/se2(x,y,radian)</span><br></pre></td></tr></table></figure><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/21.png" alt="">    </p><blockquote><p>actually: <code>se2(x,y,angle,&#39;deg&#39;) == transl2(x,y) * trot2(angle,&#39;deg&#39;)</code></p></blockquote></li><li><p><code>e2h() &amp;&amp; h2e()</code>ï¼š function e2h converts Euclid-ean coordinates to homogeneous and h2e performs the inverse conversion;</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ p1 = h2e(inv(T1) * e2h(P)) % P = [1;2]</span><br></pre></td></tr></table></figure><blockquote><p>More compactly this can be written as</p><blockquote><p>p1 = homtrans( inv(T1), P)</p></blockquote></blockquote></li><li><p>Example1: <code>pose compounding is not commutative(äº¤æ¢çš„)</code></p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">T1 = se2(1,2,30,&apos;deg&apos;)</span><br><span class="line">T2 = transl2(2,1) * trot2(0)</span><br><span class="line">T3 = T1 * T2    %This can be thought of the pose 2 with respect to the frame 1</span><br><span class="line">T4 = T2 * T1</span><br></pre></td></tr></table></figure><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/23.png" alt=""></p></li><li><p>Example2ï¼špoint with respace to 1</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">p = [3 2]&apos;</span><br><span class="line">plot_point(p)</span><br><span class="line">p1 = inv(T1) * [p;1] % = p1 = inv(T1) * e2h(p)</span><br></pre></td></tr></table></figure><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/24.png" alt=""></p></li></ul><h1 id="3DPose"><a href="#3DPose" class="headerlink" title="3DPose"></a>3DPose</h1><h2 id="Basic-concept"><a href="#Basic-concept" class="headerlink" title="Basic concept"></a>Basic concept</h2><ul><li><p>Point &amp;&amp; Pose<img src="/2019/03/25/Notes-of-Manipulation-class/14.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/15.png" alt=""></p></li><li><p>The Right-Hand Rule</p><blockquote><p>Angles increase positively in the anti-clockwise direction</p></blockquote><p>  <img src="/2019/03/25/Notes-of-Manipulation-class/13.png" alt=""></p><h2 id="Relative-Poses-1"><a href="#Relative-Poses-1" class="headerlink" title="Relative Poses"></a>Relative Poses</h2></li><li><p>Relative position/pose<img src="/2019/03/25/Notes-of-Manipulation-class/16.png" alt=""></p></li><li><p>Pose algebra<img src="/2019/03/25/Notes-of-Manipulation-class/17.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/18.png" alt=""></p></li></ul><h2 id="Representing-Orientation-in-3-Dimensions"><a href="#Representing-Orientation-in-3-Dimensions" class="headerlink" title="Representing Orientation in 3-Dimensions"></a>Representing Orientation in 3-Dimensions</h2><h3 id="Orthonormal-Rotation-Matrix"><a href="#Orthonormal-Rotation-Matrix" class="headerlink" title="Orthonormal Rotation Matrix"></a>Orthonormal Rotation Matrix</h3><ul><li><p>3Ã—3 orthonormal matrix<br><img src="/2019/03/25/Notes-of-Manipulation-class/25.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/26.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/61.png" alt=""></p></li><li><p>Coding part</p><blockquote><p><code>rotx()</code>ï¼š3 dimensional rotation matrix</p></blockquote>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ R = rotx(pi/2)</span><br><span class="line">$ R = rotx(45, &apos;deg&apos;)</span><br></pre></td></tr></table></figure><blockquote><p><code>trplot() &amp;&amp; tranimate()</code>ï¼šdisplay a 3d transformation</p></blockquote>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ trplot(R)</span><br><span class="line">$ tranimate(R)</span><br></pre></td></tr></table></figure></li></ul><h3 id="Three-Angle-Representations"><a href="#Three-Angle-Representations" class="headerlink" title="Three-Angle Representations"></a>Three-Angle Representations</h3><ul><li><p>Rotation sequences<br><img src="/2019/03/25/Notes-of-Manipulation-class/28.png" alt=""></p></li><li><p>Euler anglesï¼šEulerâ€™s rotation theorem requires successive rotation about three axes such that notwo successive rotations are about the same axis.   </p><blockquote><p><strong>Representation</strong></p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/27.png" alt=""></p></blockquote></blockquote><blockquote><p><strong>Coding</strong>:</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/29.png" alt=""></p></blockquote></blockquote><blockquote><p><strong>if Î¸ is negative</strong></p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/30.png" alt=""></p></blockquote></blockquote><blockquote><p><strong>if Î¸=0</strong></p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/31.png" alt=""></p></blockquote></blockquote></li><li><p>Cardan angles/Roll-Pitch-Yaw angles</p><blockquote><p><strong>Representation</strong></p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/32.png" alt=""></p></blockquote></blockquote><blockquote><p><strong>Coding</strong></p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/33.png" alt=""></p></blockquote></blockquote></li><li>Fundamental problemï¼šSingularities and Gimbal Lock<blockquote><p>This occurs when the rotational axis of the middle term in the sequence becomes parallel to the rotation axis of the first or third term. </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/34.png" alt=""></p></blockquote></blockquote></li></ul><h3 id="Two-Vector-Representation"><a href="#Two-Vector-Representation" class="headerlink" title="Two Vector Representation"></a>Two Vector Representation</h3><ul><li>Two Vector Representation<blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/35.png" alt=""></p></blockquote></li></ul><h3 id="Rotation-about-an-Arbitrary-Vector"><a href="#Rotation-about-an-Arbitrary-Vector" class="headerlink" title="Rotation about an Arbitrary Vector"></a>Rotation about an Arbitrary Vector</h3><ul><li><p>Any two independent orthonormal coordinate frames can be related by a single rotation about some axis.</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/47.png" alt=""></p></blockquote></li><li><p>Finding the axis;</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/48.png" alt=""></p></blockquote></li><li><p>Coding part: <code>tr2angvec(R)ã€eig(R)ã€angvec2r(pi/2, [1 0 0])</code></p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/49.png" alt=""><br><img src="/2019/03/25/Notes-of-Manipulation-class/50.png" alt=""><br><img src="/2019/03/25/Notes-of-Manipulation-class/51.png" alt=""></p></blockquote></li></ul><h3 id="Quaternion"><a href="#Quaternion" class="headerlink" title="Quaternion"></a>Quaternion</h3><ul><li><p>The quaternion is an extension of the complex number â€“ a hyper-complex number â€“ and is written as a scalar plus a vector</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/52.png" alt=""><br><img src="/2019/03/25/Notes-of-Manipulation-class/53.png" alt=""></p></blockquote></li><li><p>Coding partï¼š<code>Quaternion()</code> is a class</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/54.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/55.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/56.png" alt=""></p></blockquote></li></ul><h2 id="Combining-Translation-and-Orientation"><a href="#Combining-Translation-and-Orientation" class="headerlink" title="Combining Translation and Orientation"></a>Combining Translation and Orientation</h2><h3 id="Representing-pose"><a href="#Representing-pose" class="headerlink" title="Representing pose"></a>Representing pose</h3><ul><li>Pose<blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/57.png" alt=""></p></blockquote></li></ul><h3 id="Vecotr-Quaternion"><a href="#Vecotr-Quaternion" class="headerlink" title="Vecotr-Quaternion"></a>Vecotr-Quaternion</h3><ul><li>Vecotr-Quaternion<blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/58.png" alt=""></p></blockquote></li></ul><h3 id="homogeneous-transformation-matrix"><a href="#homogeneous-transformation-matrix" class="headerlink" title="homogeneous transformation matrix"></a>homogeneous transformation matrix</h3><ul><li><p>Form</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/59.png" alt=""></p></blockquote></li><li><p>Properties</p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/60.png" alt=""></p></blockquote></li><li><p>Coding partï¼š<code>transl(x,y,z)ã€trots(pi/20)</code>  <img src="/2019/03/25/Notes-of-Manipulation-class/62.png" alt=""></p></li></ul><h2 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h2><ul><li>Warpping up<blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/63.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/64.png" alt=""></p></blockquote></li></ul><h2 id="Coding-part"><a href="#Coding-part" class="headerlink" title="Coding part"></a>Coding part</h2><ul><li><p><code>rotx()</code>ï¼š3 dimensional rotation matrix</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ R = rotx(pi/2)</span><br><span class="line">$ R = rotx(45, &apos;deg&apos;)</span><br></pre></td></tr></table></figure></li><li><p><code>trplot() &amp;&amp; tranimate()</code>ï¼šdisplay a 3d transformation</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ trplot(R)</span><br><span class="line">$ tranimate(R)</span><br></pre></td></tr></table></figure></li></ul><h1 id="Time-and-Motion"><a href="#Time-and-Motion" class="headerlink" title="Time and Motion"></a>Time and Motion</h1><h2 id="Trajectories"><a href="#Trajectories" class="headerlink" title="Trajectories"></a>Trajectories</h2><ul><li>An important characteristic of a trajectory is that is <strong>smooth</strong> â€“ position and orientation vary smoothly with time  <blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/36.png" alt=""></p></blockquote></li></ul><h3 id="Smooth-One-Dimensional-Trajectories"><a href="#Smooth-One-Dimensional-Trajectories" class="headerlink" title="Smooth One-Dimensional Trajectories"></a>Smooth One-Dimensional Trajectories</h3><ul><li><p>Polynomial function of time    </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/37.png" alt=""><br><img src="/2019/03/25/Notes-of-Manipulation-class/46.png" alt=""></p></blockquote></li><li><p><code>tpoly()</code>: generates a quintic polynomial trajectory    </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/38.png" alt=""></p></blockquote><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/39.png" alt=""></p></blockquote></li><li><p><code>lspb</code>ï¼šlinear segment (constant velocity) with parabolic blends    </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/40.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/41.png" alt=""></p></blockquote></li></ul><h3 id="Multi-Dimensional-Case"><a href="#Multi-Dimensional-Case" class="headerlink" title="Multi-Dimensional Case"></a>Multi-Dimensional Case</h3><ul><li><code>mtraj()/jtraj()</code>:  extend the smooth scalar trajectory to the vector case(å¤šç»´)    <blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/42.png" alt=""></p></blockquote></li></ul><h3 id="Multi-Segment-Trajectories"><a href="#Multi-Segment-Trajectories" class="headerlink" title="Multi-Segment Trajectories"></a>Multi-Segment Trajectories</h3><ul><li><p>In robotics applications there is often a need to move smoothly along a path through one or more intermediate or via points without stopping. This might be to avoid obstacles in the workplace, or to perform a task that involves following a piecewise continuous trajectory.  </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/43.png" alt="">   </p></blockquote></li><li><p><code>mstraj()</code>ï¼š generates a multi-segment multi-axis trajectory based on a matrix of via points    </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/44.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/45.png" alt=""></p></blockquote></li></ul><h3 id="Interpolation-of-Orientation-in-3D"><a href="#Interpolation-of-Orientation-in-3D" class="headerlink" title="Interpolation of Orientation in 3D"></a>Interpolation of Orientation in 3D</h3><ul><li>A rotation matrix must be an orthogonal matrix     <blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/65.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/66.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/75.png" alt=""></p></blockquote></li><li>Quaternion interpolation     <blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/69.png" alt=""></p></blockquote></li></ul><ul><li><p><code>jtraj()/mtraj()</code>ï¼š roll-pitch-yaw angles can be interpolated    </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/67.png" alt=""></p></blockquote></li><li><p><code>interp()</code>    </p><blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/68.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/70.png" alt=""></p></blockquote></li></ul><h3 id="Cartesian-Motion"><a href="#Cartesian-Motion" class="headerlink" title="Cartesian Motion"></a>Cartesian Motion</h3><blockquote><p>Another common requirement is a smooth path between two poses in SE(3) which involves change in position as well as in orientation. In robotics this is often referred to as Cartesian motion.<br><img src="/2019/03/25/Notes-of-Manipulation-class/71.png" alt=""></p></blockquote><ul><li>Coding part    2019/4/13 10:36:21 2019/4/13 10:36:24 <blockquote><p><img src="/2019/03/25/Notes-of-Manipulation-class/72.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/73.png" alt=""><img src="/2019/03/25/Notes-of-Manipulation-class/74.png" alt=""></p></blockquote></li></ul>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/03/25/Notes-of-Manipulation-class/#disqus_thread</comments>
    </item>
    
    <item>
      <title>RNN&amp;&amp;LSTM</title>
      <link>http://yoursite.com/2019/03/24/DL_RNN-LSTM/</link>
      <guid>http://yoursite.com/2019/03/24/DL_RNN-LSTM/</guid>
      <pubDate>Sun, 24 Mar 2019 02:11:42 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a><a href="https://pytorch.org/docs/stable/nn.html#rnn" target="_blank" rel="noopener">RNN</a></h1><h2 id="ç†è§£RNNå†…éƒ¨"><a href="#ç†è§£RNNå†…éƒ¨" class="headerlink" title="ç†è§£RNNå†…éƒ¨"></a>ç†è§£RNNå†…éƒ¨</h2><ul><li><p><strong>æˆ‘ä»¬å¯ä»¥ç”¨å‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFFNNsï¼‰é‚£æ ·å»ç†è§£</strong><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/3.png" alt=""><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/1.png" alt=""><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/2.png" alt=""></p></li><li><p><strong>Backpropagation through time(BPTT)</strong><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/4.png" alt=""><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/5.png" alt=""><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/6.png" alt=""></p><blockquote><p>For n-layers, can check <a href="https://classroom.udacity.com/nanodegrees/nd101/parts/0d85c39f-2ac0-49b3-98b0-fd40e9180cf4/modules/dd68b0bb-dd81-436f-bb04-e2a34ed349b8/lessons/74236975-4329-4704-9890-85b51f3f35fa/concepts/0f22f887-59e5-4bac-a2e9-d85c4f4b1c69" target="_blank" rel="noopener">here</a>  </p></blockquote></li></ul><h1 id="LSTM"><a href="#LSTM" class="headerlink" title="LSTM"></a>LSTM</h1><h1 id="Word-Embeddings"><a href="#Word-Embeddings" class="headerlink" title="Word Embeddings"></a>Word Embeddings</h1><h2 id="Basic"><a href="#Basic" class="headerlink" title="Basic"></a>Basic</h2><ul><li>Reduce the dimensionality of text data.  </li><li>Learn some interesting traits about words in a vocabulary.   <blockquote><p><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/7.png" alt=""></p></blockquote></li></ul><h2 id="Embedding-Weight-Matrix-Lookup-table"><a href="#Embedding-Weight-Matrix-Lookup-table" class="headerlink" title="Embedding Weight Matrix/Lookup table"></a>Embedding Weight Matrix/Lookup table</h2><ul><li><p>The embedding can graetly improve the ability of networks to learn from text data, by representing that data as lower-dimensional vectors.  </p><blockquote><p><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/8.png" alt=""><br><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/9.png" alt=""><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/10.png" alt=""></p></blockquote></li><li><p>Embedding lookup    </p><blockquote><p><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/11.png" alt=""></p></blockquote></li></ul><h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><blockquote><p>The Word2Vec algorithm finds much more efficient representations by finding vectors that represent the words. These vectors also contain semantic information about the words.</p></blockquote><ul><li><strong>Two architectures for implementing Word2Vec:</strong>    <blockquote><p><img src="/2019/03/24/DL_RNN-LSTM/RNN-LSTM/12.png" alt=""></p></blockquote></li></ul><h1 id="CODING"><a href="#CODING" class="headerlink" title="CODING"></a>CODING</h1><ol><li>å°†æ•°æ®feedç»™FCå±‚ä¹‹å‰ï¼Œä¸€èˆ¬éœ€è¦è¿›è¡Œ<em>â€œé™ç»´â€</em><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># shape output to be (batch_size*seq_length, hidden_dim)</span><br><span class="line">r_out = r_out.view(-1, self.hidden_dim)  </span><br><span class="line"># sometime you may need to use contiguous to reshape the output</span><br><span class="line">r_out = r_out.contiguous().view(-1, self.hidden_dim)</span><br></pre></td></tr></table></figure></li></ol>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/03/24/DL_RNN-LSTM/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Data processing with numpy or pytorch</title>
      <link>http://yoursite.com/2019/03/09/numpy-and-pytorch-in-coding/</link>
      <guid>http://yoursite.com/2019/03/09/numpy-and-pytorch-in-coding/</guid>
      <pubDate>Sat, 09 Mar 2019 04:19:03 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Numpy"><a href="#Numpy" class="headerlink" title="Numpy"></a>Numpy</h1><h2 id="Numpyä»æ•°å€¼èŒƒå›´åˆ›å»ºæ•°ç»„ï¼šarange-ã€linspace-ã€logsapce"><a href="#Numpyä»æ•°å€¼èŒƒå›´åˆ›å»ºæ•°ç»„ï¼šarange-ã€linspace-ã€logsapce" class="headerlink" title="Numpyä»æ•°å€¼èŒƒå›´åˆ›å»ºæ•°ç»„ï¼šarange()ã€linspace()ã€logsapce()"></a><a href="http://www.runoob.com/numpy/numpy-array-from-numerical-ranges.html" target="_blank" rel="noopener">Numpyä»æ•°å€¼èŒƒå›´åˆ›å»ºæ•°ç»„ï¼šarange()ã€linspace()ã€logsapce()</a></h2><ul><li><code>numpy.arange(start=0, stop, step=1, dtype)</code>:  start ä¸ stop æŒ‡å®šçš„èŒƒå›´ä»¥åŠ step è®¾å®šçš„æ­¥é•¿ï¼Œç”Ÿæˆä¸€ä¸ª ndarray,ä¸åŒ…å«<code>stop</code>å€¼ï¼›  </li><li><code>np.linspace(start, stop, num=50, endpoint=True, retstep=False, dtype=None)</code>:    åˆ›å»ºä¸€ä¸ªç­‰å·®æ•°åˆ—æ„æˆçš„ä¸€ç»´æ•°ç»„ï¼Œ<code>num</code>ä¸ºæ ·æœ¬é‡ï¼›  </li><li><code>np.logspace(start, stop, num=50, endpoint=True, base=10.0, dtype=None)</code>: åˆ›å»ºä¸€ä¸ªç­‰æ¯”æ•°åˆ—æ„æˆçš„ä¸€ç»´æ•°ç»„ï¼Œ<code>base</code>ä¸ºåº•ï¼›</li></ul><h1 id="Pytorch"><a href="#Pytorch" class="headerlink" title="Pytorch"></a>Pytorch</h1><h2 id="pytorchä¸­torch-view-ã€squeeze-ã€unsqueeze-ã€max"><a href="#pytorchä¸­torch-view-ã€squeeze-ã€unsqueeze-ã€max" class="headerlink" title="pytorchä¸­torch.view()ã€squeeze()ã€unsqueeze()ã€max()"></a><a href="https://blog.csdn.net/lanse_zhicheng/article/details/79148678#commentBox" target="_blank" rel="noopener">pytorchä¸­torch.view()ã€squeeze()ã€unsqueeze()ã€max()</a></h2><p>numel()<br>permute()<br>tqdmfireç½‘ç»œå‚æ•°åˆå§‹åŒ–é—®é¢˜<a href="https://cloud.tencent.com/developer/ask/51836" target="_blank" rel="noopener">meshgrid()</a>stackravelnp.newaxiswhereastype()</p><p>numpy.prob()è¿ä¹˜assert</p><p>a.shape=(1,4,4)a[:,:,0::4].shape=(1,4,1)è€Œa[:,:,0].shape=(1,4)</p><p>if set model.eval() â€”â€”&gt; model.training = Flase</p><p><a href="https://blog.csdn.net/weixin_41010198/article/details/84828022" target="_blank" rel="noopener">pythonç±»æ–¹æ³•ä¸­ä½¿ç”¨ï¼šä¿®é¥°ç¬¦@staticmethodå’Œ@classmethodçš„ä½œç”¨ä¸åŒºåˆ«ï¼Œè¿˜æœ‰è£…é¥°å™¨@propertyçš„ä½¿ç”¨</a></p><p><a href="https://blog.csdn.net/u011501388/article/details/84062483" target="_blank" rel="noopener">PyTorchä¹‹å‰å‘ä¼ æ’­å‡½æ•°forward</a></p><p>open.cvè¯»å…¥å›¾ç‰‡çš„å°ºå¯¸æ˜¯ï¼ˆH,W,Cï¼‰</p><p>Input type(torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be he same:::åŸå› å¯èƒ½æ˜¯modelæ”¾è¿›äº†GPUè€Œè¾“å…¥æ•°æ®æ²¡æœ‰æ”¾åˆ°GPUã€‚</p><p>expected object of backend CPU but got backend CUDA    for sequence element 1 in sequence argument at position #1 â€˜tensorsâ€™:CUDAä¸CPUçš„æ•°æ®ä¸èƒ½æ··åœ¨ä¸€èµ·è¿ç®—ï¼Œä¸ä¼šè‡ªç”±è½¬æ¢ï¼Œ<a href="https://www.zhihu.com/question/67209417" target="_blank" rel="noopener">é—¨</a></p><p>when set model.eval(), self.training/model.training = False?</p><p><a href="https://discuss.pytorch.org/t/torch-from-numpy-not-support-negative-strides/3663" target="_blank" rel="noopener">ValueError: some of the strides of a given numpy array are negative. This is currently not supported, but will be added in future releases.</a> </p>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/03/09/numpy-and-pytorch-in-coding/#disqus_thread</comments>
    </item>
    
    <item>
      <title>Deep learning in Pytorch</title>
      <link>http://yoursite.com/2019/03/05/pytorch%EF%BC%9ADeeplearning-in-Pytorch-Udacity/</link>
      <guid>http://yoursite.com/2019/03/05/pytorch%EF%BC%9ADeeplearning-in-Pytorch-Udacity/</guid>
      <pubDate>Tue, 05 Mar 2019 11:40:24 GMT</pubDate>
      <description>
      
        
        
          &lt;link rel=&quot;stylesheet&quot; class=&quot;aplayer-secondary-style-marker&quot; href=&quot;\assets\css\APlayer.min.css&quot;&gt;&lt;script src=&quot;\assets\js\APlayer.min.js&quot; cla
        
      
      </description>
      
      <content:encoded><![CDATA[<link rel="stylesheet" class="aplayer-secondary-style-marker" href="\assets\css\APlayer.min.css"><script src="\assets\js\APlayer.min.js" class="aplayer-secondary-script-marker"></script><h1 id="Architectures"><a href="#Architectures" class="headerlink" title="Architectures"></a>Architectures</h1><h1 id="Utility-tool"><a href="#Utility-tool" class="headerlink" title="Utility tool"></a>Utility tool</h1><h2 id="check-weights-or-bias"><a href="#check-weights-or-bias" class="headerlink" title="check weights or bias"></a>check weights or bias</h2><ol><li>é€šè¿‡<em>print</em> <code>model.state_dict()</code>æˆ–<code>model.named_parameters()</code>æŸ¥çœ‹æ‰€æœ‰å‚æ•°ï¼Œä¿¡æ¯åŒ…æ‹¬<code>name</code>å’Œ<code>params</code>ï¼Œç„¶åä½¿ç”¨ç‚¹è¿ç®—ç¬¦<code>.</code>æŸ¥çœ‹ç›¸åº”çš„å‚æ•°ï¼›</li><li><p>é€šè¿‡å®˜ç½‘æŸ¥çœ‹ç›¸åº”ç½‘ç»œæ¨¡å—å…·æœ‰çš„<code>variables</code>ï¼Œç„¶åä½¿ç”¨ç‚¹è¿ç®—ç¬¦<code>.</code>æŸ¥çœ‹ç›¸åº”çš„å‚æ•°ï¼› </p> <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">model.fc.weight</span><br><span class="line">model.fc.bias</span><br><span class="line">model.rnn.weight_ih_l0</span><br><span class="line">model.rnn.bias_hh_l1</span><br></pre></td></tr></table></figure></li></ol><h2 id="Running-with-GPU"><a href="#Running-with-GPU" class="headerlink" title="Running with GPU"></a>Running with GPU</h2><ul><li><p>æŸ¥çœ‹GPUæ˜¯å¦å¯ç”¨ï¼Œç„¶åä½¿ç”¨<code>.to()</code>ä½¿ç”¨ç›¸åº”deviceï¼š</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">model.to(device)</span><br></pre></td></tr></table></figure></li><li><p>å¸¸ç”¨GPUå‘½ä»¤</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">torch.cuda.is_available()</span><br><span class="line">cudaæ˜¯å¦å¯ç”¨ï¼›</span><br><span class="line"></span><br><span class="line">torch.cuda.device_count()</span><br><span class="line">è¿”å›gpuæ•°é‡ï¼›</span><br><span class="line"></span><br><span class="line">torch.cuda.get_device_name(0)</span><br><span class="line">è¿”å›gpuåå­—ï¼Œè®¾å¤‡ç´¢å¼•é»˜è®¤ä»0å¼€å§‹ï¼›</span><br><span class="line"></span><br><span class="line">torch.cuda.current_device()</span><br><span class="line">è¿”å›å½“å‰è®¾å¤‡ç´¢å¼•ï¼›</span><br></pre></td></tr></table></figure></li></ul><h2 id="ä¿å­˜æˆ–åŠ è½½æ¨¡å‹"><a href="#ä¿å­˜æˆ–åŠ è½½æ¨¡å‹" class="headerlink" title="ä¿å­˜æˆ–åŠ è½½æ¨¡å‹"></a>ä¿å­˜æˆ–åŠ è½½æ¨¡å‹</h2><ul><li><p>å¿«é€Ÿä¿å­˜æ¨¡å‹ï¼š</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">torch.save(model.state_dict(), &apos;path/file_name.pth&apos;)</span><br></pre></td></tr></table></figure></li><li><p>è¯¦ç»†ä¿å­˜ï¼šåŒ…æ‹¬å…¶ä»–ä¸€ä¸‹ä¿¡æ¯</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">checkpoints=&#123;&apos;label&apos;: model.n_label,</span><br><span class="line"> &apos;input_size&apos;: model.input_size,</span><br><span class="line"> &apos;state_dict&apos;: model.state_dict()&#125;</span><br><span class="line">with open(os.path.join(args.save+fold,model_name), &apos;wb&apos;) as f:</span><br><span class="line">torch.save(checkpoint, f)</span><br></pre></td></tr></table></figure></li><li><p>åŠ è½½ï¼š</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">model.load_state_dict((torch.load(path/file_name.pth)))</span><br></pre></td></tr></table></figure></li></ul><h2 id="è¿ç§»å­¦ä¹ ï¼štorchvision-models"><a href="#è¿ç§»å­¦ä¹ ï¼štorchvision-models" class="headerlink" title="è¿ç§»å­¦ä¹ ï¼štorchvision.models"></a>è¿ç§»å­¦ä¹ ï¼š<code>torchvision.models</code></h2><ul><li><p>ç›´æ¥ä»<code>torchvision</code>æ¨¡å—é‡ŒåŠ è½½æ¨¡å‹ï¼š</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import torchvision.models as models/ from torchvision import models</span><br><span class="line">model = models.vgg16(pretrained=True/ not args.caffe_pretrain)</span><br></pre></td></tr></table></figure></li><li><p>freeze parameters1</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for param in model.features.parameters():</span><br><span class="line">param.require_grad = False</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line">- freeze specified parameter2</span><br></pre></td></tr></table></figure><h1 id="delete-the-last-MaxPooling-layer"><a href="#delete-the-last-MaxPooling-layer" class="headerlink" title="delete the last MaxPooling layer"></a>delete the last MaxPooling layer</h1><h1 id="freeze-the-first-4-convs"><a href="#freeze-the-first-4-convs" class="headerlink" title="freeze the first 4 convs"></a>freeze the first 4 convs</h1><p>  features = list(model.features)[:30]   for layer in features[:10]: </p><pre><code>for p in layer.parameters():     p.requires_grad = False </code></pre><p>  features = nn.Sequential(*features)</p>  <figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&gt; æœ€å¥½æ£€æŸ¥ä¸€ä¸‹æ˜¯å¦â€œå†»ç»“â€äº†å‚æ•°ï¼Œå¿…è¦æ—¶åœ¨`optimizer`ä½¿ç”¨`filter`è¿‡æ»¤ä¸€é,[ä¼ é€é—¨][filter]ï¼š   </span><br><span class="line">&gt; `optimizer.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)`</span><br><span class="line"></span><br><span class="line">- åˆ é™¤æˆ–å¢åŠ layerï¼šè½¬æˆ`list`æ–¹ä¾¿æ“ä½œï¼Œåé¢å†ä½¿ç”¨`nn.Sequential(*list)`æ„å»ºæ¨¡å‹ï¼Œå…¶ä¸­çš„`*`æ˜¯å°†åˆ—è¡¨æˆ–å…ƒç»„ï¼ˆå¯èƒ½é€‚åˆå…¶ä»–ç±»å‹ï¼‰æ•°æ®æ‹†åˆ†ï¼›</span><br><span class="line"></span><br><span class="line">``` </span><br><span class="line"># delete the last Linear layer </span><br><span class="line">classifier = list(model.classifier) </span><br><span class="line">in_feature = classifier[6].in_feature</span><br><span class="line">del classifier[6] </span><br><span class="line">if not args.use_drop: </span><br><span class="line">del classifier[2] </span><br><span class="line">del classifier[5] </span><br><span class="line">classifier = nn.Sequential(*classifier) </span><br><span class="line">classifier.add_module(str(6), nn.Linear(in_feature, 10))</span><br><span class="line">``` </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># python #</span><br><span class="line">## ä½¿ç”¨[osæ¨¡å—][os]åˆ›å»ºæ–‡ä»¶å¤¹ ##</span><br><span class="line">&gt; ä¸€èˆ¬å…ˆä½¿ç”¨`os.path.exists(path)`æ¥æ£€æŸ¥ç›¸åº”æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨</span><br><span class="line">1. ä½¿ç”¨`os.mkdir(path)`åˆ›å»ºç›®å½•ï¼›</span><br><span class="line">2. ä½¿ç”¨`os.makedirs(path)`é€’å½’åˆ›å»ºç›®å½•ï¼›</span><br></pre></td></tr></table></figure><p>  if not os.path.exists(path):</p><pre><code>os.makedirs(path)</code></pre><p>  <code>`</code></p></li></ul>]]></content:encoded>
      
      <comments>http://yoursite.com/2019/03/05/pytorch%EF%BC%9ADeeplearning-in-Pytorch-Udacity/#disqus_thread</comments>
    </item>
    
  </channel>
</rss>
